<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>速读论文M2BEV | 个人博客</title>
<meta name=keywords content="papper"><meta name=description content="摘要：速读论文M2BEV: Multi-Camera Joint 3D Detection and Segmentation with Unified Bird’s-Eye View Representation。"><meta name=author content="Yangly0"><link rel=canonical href=https://yangly0.github.io/posts/20250206094054/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://yangly0.github.io/images/favicon/favicon.png><link rel=icon type=image/png sizes=16x16 href=https://yangly0.github.io/images/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://yangly0.github.io/images/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://yangly0.github.io/images/favicon/apple-touch-icon.png><link rel=mask-icon href=https://yangly0.github.io/images/favicon/favicon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://yangly0.github.io/posts/20250206094054/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.css integrity=sha384-zh0CIslj+VczCZtlzBcjt5ppRcsAmDnRem7ESsYwWwg3m/OaJ2l4x7YBZl9Kxxib crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.js integrity=sha384-Rma6DA2IPUwhNxmrB/7S3Tno0YY7sFu9WSYMCuulLhIqYSGZ2gKCJWIqhBWqMQfh crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/contrib/auto-render.min.js integrity=sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><meta property="og:url" content="https://yangly0.github.io/posts/20250206094054/"><meta property="og:site_name" content="个人博客"><meta property="og:title" content="速读论文M2BEV"><meta property="og:description" content="摘要：速读论文M2BEV: Multi-Camera Joint 3D Detection and Segmentation with Unified Bird’s-Eye View Representation。"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-02-06T09:40:54+00:00"><meta property="article:modified_time" content="2025-02-06T09:40:54+00:00"><meta property="article:tag" content="Papper"><meta property="og:image" content="https://yangly0.github.io/images/favicon/favicon.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://yangly0.github.io/images/favicon/favicon.png"><meta name=twitter:title content="速读论文M2BEV"><meta name=twitter:description content="摘要：速读论文M2BEV: Multi-Camera Joint 3D Detection and Segmentation with Unified Bird’s-Eye View Representation。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://yangly0.github.io/posts/"},{"@type":"ListItem","position":2,"name":"速读论文M2BEV","item":"https://yangly0.github.io/posts/20250206094054/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"速读论文M2BEV","name":"速读论文M2BEV","description":"摘要：速读论文M2BEV: Multi-Camera Joint 3D Detection and Segmentation with Unified Bird’s-Eye View Representation。\n","keywords":["papper"],"articleBody":"摘要：速读论文M2BEV: Multi-Camera Joint 3D Detection and Segmentation with Unified Bird’s-Eye View Representation。\n日期：Apr 2022 作者：Enze Xie 来源：香港大学和NVIDIA 链接：https://arxiv.org/abs/2204.05088 代码：https://xieenze.github.io/projects/m2bev/ 思考 问题: 文章为了解决什么问题；\n方法: 文章提出了什么方法和技术；\n结论: 文章结论即 数据集 + 评价 指标；\n优化：还有什么值得改进与优化的。\n理解 论文读完的感受与体会，比如该方法借鉴了什么思想，方法是不是新颖，实验怎么做的，讨论的变量是什么，还有其他值得读的文献。\n贡献：\n（1）一种高效的 BEV 编码器设计，可减少体素特征图的空间维度。\n（2）一种动态框分配策略，使用学习匹配来分配带有锚点的真实 3D 框。\n（3）BEV 中心性重新加权，通过更大的权重进行更远的预测。\n（4）大规模 2D 检测预训练和辅助监督。\n1、M2BEV 架构：2D Image Encoder + 2D3D Projection + 3D BEV Encoder + 3D Detection Head + BEV Segmentation Head。\n2D Image Encoder：ResNet CNNBackBone + FPN，大小为$\\frac{H}{2^{i+1}} \\times \\frac{W}{2^{i+1}}$的四层级特征F1，F2，F3，F4，再上采样到H/4 x W/4，再1x1 Conv 融合成F 2D3D Projection：从$F \\in R^{N\\times \\frac{H}{4} \\ times \\frac{W}{4} \\times C}$ ","wordCount":"86","inLanguage":"en","image":"https://yangly0.github.io/images/favicon/favicon.png","datePublished":"2025-02-06T09:40:54Z","dateModified":"2025-02-06T09:40:54Z","author":{"@type":"Person","name":"Yangly0"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://yangly0.github.io/posts/20250206094054/"},"publisher":{"@type":"Organization","name":"个人博客","logo":{"@type":"ImageObject","url":"https://yangly0.github.io/images/favicon/favicon.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://yangly0.github.io/ accesskey=h title="个人博客 (Alt + H)">个人博客</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://yangly0.github.io/posts/ title=文章><span>文章</span></a></li><li><a href=https://yangly0.github.io/about/ title=关于><span>关于</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://yangly0.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://yangly0.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">速读论文M2BEV</h1><div class=post-meta><span title='2025-02-06 09:40:54 +0000 UTC'>February 6, 2025</span>&nbsp;·&nbsp;Yangly0</div></header><div class=post-content><p>摘要：速读论文M2BEV: Multi-Camera Joint 3D Detection and Segmentation with Unified Bird’s-Eye View Representation。</p><pre tabindex=0><code>日期：Apr 2022
作者：Enze Xie
来源：香港大学和NVIDIA
链接：https://arxiv.org/abs/2204.05088
代码：https://xieenze.github.io/projects/m2bev/
</code></pre><h2 id=思考>思考<a hidden class=anchor aria-hidden=true href=#思考>#</a></h2><p>问题: 文章为了解决什么问题；</p><p>方法: 文章提出了什么方法和技术；</p><p>结论: 文章结论即 数据集 + 评价 指标；</p><p>优化：还有什么值得改进与优化的。</p><h2 id=理解>理解<a hidden class=anchor aria-hidden=true href=#理解>#</a></h2><p>论文读完的感受与体会，比如该方法借鉴了什么思想，方法是不是新颖，实验怎么做的，讨论的变量是什么，还有其他值得读的文献。</p><p>贡献：</p><p>（1）一种高效的 BEV 编码器设计，可减少体素特征图的空间维度。</p><p>（2）一种动态框分配策略，使用学习匹配来分配带有锚点的真实 3D 框。</p><p>（3）BEV 中心性重新加权，通过更大的权重进行更远的预测。</p><p>（4）大规模 2D 检测预训练和辅助监督。</p><p>1、M2BEV 架构：2D Image Encoder + 2D3D Projection + 3D BEV Encoder + 3D Detection Head + BEV Segmentation Head。</p><ul><li>2D Image Encoder：ResNet CNNBackBone + FPN，大小为$\frac{H}{2^{i+1}} \times \frac{W}{2^{i+1}}$的四层级特征F1，F2，F3，F4，再上采样到H/4 x W/4，再1x1 Conv 融合成F</li><li>2D3D Projection：从$F \in R^{N\times \frac{H}{4} \ times \frac{W}{4} \times C}$</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://yangly0.github.io/tags/papper/>Papper</a></li></ul><nav class=paginav><a class=prev href=https://yangly0.github.io/posts/20250207230532/><span class=title>« Prev</span><br><span>C++ 如何排查多线程中的死锁问题？</span>
</a><a class=next href=https://yangly0.github.io/posts/20250205211553/><span class=title>Next »</span><br><span>速读论文Fast-Bev</span></a></nav></footer><script src=https://utteranc.es/client.js repo=Yangly0/hugo-utterances issue-term=pathname theme=github-light crossorigin=anonymous async></script></article></main><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>